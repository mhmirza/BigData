# BigData

This portfolio captures the work I completed for a course, Big Data and Large Scale Computing, at Carnegie Mellon University in Fall 2021. To view my GitHub repository, please click [here](https://github.com/mhmirza/BigData). The work done here involves hands-on experience with MapReduce and Apache Spark using real-world datasets. Each of the assignment below encapsulates a thorough grounding in the technologies and best practices used in Big Data Machine Learning.

# What I hope to learn?

From the course, Big Data & Large Scale Computing, I wish to garner the knowledge and practical skills to develop big data/ machine learning solutions with the state-of-the-art tools, particularly those in the Spark environment, with a focus on programming models in MLlib, GraphX, and SparkSQL.

# Portfolio

Here are the assignments that I completed during the course of this class.

# Case Studies

To view code for each, please click on the hyperlinks below.

I. The volume of unstructured text in existence is growing dramatically, and Spark is an excellent tool for analyzing this type of data. In this homework, we will write code that calculates the most common words in the Complete Works of William Shakespeare retrieved from Project Gutenberg.

[Introduction to PySpark and RDDs](https://github.com/mhmirza/BigData/blob/main/Assignment%201%20-%20Pyspark%20RDDs.ipynb)

II. This assignment covers a common supervised learning pipeline, using a modified version of the Million Song Dataset from the UCI Machine Learning Repository. Our goal is to train a linear regression model to predict the release year of a song given a set of audio features.

[Linear Regression](https://github.com/mhmirza/BigData/blob/main/Assignment%202%20-%20Linear%20Regression.ipynb)

III. This assignment covers the steps for creating a click-through rate (CTR) prediction pipeline. We will work with the Criteo Labs dataset that was used for a recent Kaggle competition.

[Click-Through Rate Prediction](https://github.com/mhmirza/BigData/blob/main/Assignment%203%20-%20CTR.ipynb)

IV. This assignment delves into exploratory analysis of neuroscience data, specifically using principal component analysis (PCA) and feature-based aggregation. We will use a dataset of light-sheet imaging recorded by the Ahrens Lab at Janelia Research Campus, and hosted on the CodeNeuro data repository.

[Principal Component Analysis](https://github.com/mhmirza/BigData/blob/main/Assignment%204%20-%20PCA.ipynb)

# Final Project

Brief Description: "To prepare for large public health emergencies, the Allegheny County is prioritizing the list of Points of Dispense (PODs) to open, which are used to distribute essential supplies and medicines to the public during such emergencies. Your goal for this project is to formulate a facility location model, and optimally select a list of PODs from the candidate sites. You need to compare two different formulations: minimizing the total/weighted travel distance of the population, and minimizing the maximum travel distance for anyone."

Please click on the hyperlinks below to view the project details:

Project Prompt
Project Report & Mathematical Formulation
Python Code
Data Files
